{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0d424baa-4a2e-4b1f-8175-a499b87d86dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from string import punctuation\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.model_selection import KFold,cross_val_score,train_test_split\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import spacy\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from tensorflow.keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6597b527-0dcf-47cc-bbf3-64d40921b0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download(\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bce424e1-b106-4dd5-9cb3-8a6092bf9896",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>helpful</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>reviewTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A2IBPI20UZIR0U</td>\n",
       "      <td>1384719342</td>\n",
       "      <td>cassandra tu \"Yeah, well, that's just like, u...</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>Not much to write about here, but it does exac...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>good</td>\n",
       "      <td>1393545600</td>\n",
       "      <td>02 28, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A14VAT5EAX3D9S</td>\n",
       "      <td>1384719342</td>\n",
       "      <td>Jake</td>\n",
       "      <td>[13, 14]</td>\n",
       "      <td>The product does exactly as it should and is q...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Jake</td>\n",
       "      <td>1363392000</td>\n",
       "      <td>03 16, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A195EZSQDW3E21</td>\n",
       "      <td>1384719342</td>\n",
       "      <td>Rick Bennette \"Rick Bennette\"</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>The primary job of this device is to block the...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>It Does The Job Well</td>\n",
       "      <td>1377648000</td>\n",
       "      <td>08 28, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A2C00NNG1ZQQG2</td>\n",
       "      <td>1384719342</td>\n",
       "      <td>RustyBill \"Sunday Rocker\"</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>Nice windscreen protects my MXL mic and preven...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>GOOD WINDSCREEN FOR THE MONEY</td>\n",
       "      <td>1392336000</td>\n",
       "      <td>02 14, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A94QU4C90B1AX</td>\n",
       "      <td>1384719342</td>\n",
       "      <td>SEAN MASLANKA</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>This pop filter is great. It looks and perform...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>No more pops when I record my vocals.</td>\n",
       "      <td>1392940800</td>\n",
       "      <td>02 21, 2014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID        asin  \\\n",
       "0  A2IBPI20UZIR0U  1384719342   \n",
       "1  A14VAT5EAX3D9S  1384719342   \n",
       "2  A195EZSQDW3E21  1384719342   \n",
       "3  A2C00NNG1ZQQG2  1384719342   \n",
       "4   A94QU4C90B1AX  1384719342   \n",
       "\n",
       "                                       reviewerName   helpful  \\\n",
       "0  cassandra tu \"Yeah, well, that's just like, u...    [0, 0]   \n",
       "1                                              Jake  [13, 14]   \n",
       "2                     Rick Bennette \"Rick Bennette\"    [1, 1]   \n",
       "3                         RustyBill \"Sunday Rocker\"    [0, 0]   \n",
       "4                                     SEAN MASLANKA    [0, 0]   \n",
       "\n",
       "                                          reviewText  overall  \\\n",
       "0  Not much to write about here, but it does exac...      5.0   \n",
       "1  The product does exactly as it should and is q...      5.0   \n",
       "2  The primary job of this device is to block the...      5.0   \n",
       "3  Nice windscreen protects my MXL mic and preven...      5.0   \n",
       "4  This pop filter is great. It looks and perform...      5.0   \n",
       "\n",
       "                                 summary  unixReviewTime   reviewTime  \n",
       "0                                   good      1393545600  02 28, 2014  \n",
       "1                                   Jake      1363392000  03 16, 2013  \n",
       "2                   It Does The Job Well      1377648000  08 28, 2013  \n",
       "3          GOOD WINDSCREEN FOR THE MONEY      1392336000  02 14, 2014  \n",
       "4  No more pops when I record my vocals.      1392940800  02 21, 2014  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data =  pd.read_csv(r\"C:\\Users\\USUARIO\\Downloads\\Musical_instruments_reviews.csv\")\n",
    "data_cleaned = data.dropna(subset=[\"reviewText\"])\n",
    "data_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f6d25a7-14bb-48ad-8191-84bfd6a7c18e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 10254 entries, 0 to 10260\n",
      "Data columns (total 9 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   reviewerID      10254 non-null  object \n",
      " 1   asin            10254 non-null  object \n",
      " 2   reviewerName    10227 non-null  object \n",
      " 3   helpful         10254 non-null  object \n",
      " 4   reviewText      10254 non-null  object \n",
      " 5   overall         10254 non-null  float64\n",
      " 6   summary         10254 non-null  object \n",
      " 7   unixReviewTime  10254 non-null  int64  \n",
      " 8   reviewTime      10254 non-null  object \n",
      "dtypes: float64(1), int64(1), object(7)\n",
      "memory usage: 801.1+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(data_cleaned.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b104584-c002-42c2-8cbc-067f9f0069c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "much write exactly suppose filter pop sound recording much crisp one low price pop filter amazon might well buy honestly work despite pricing\n"
     ]
    }
   ],
   "source": [
    "#Removing stop-words, punctuations and lemmatizing the words to increase model performance\n",
    "stop_words = set(nltk.corpus.stopwords.words(\"english\"))\n",
    "stop_words.update(punctuation)\n",
    "tokenizer = nltk.tokenize.RegexpTokenizer(r'\\w+')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def get_wordnet_pos(treebank_tag):\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN  \n",
    "def preprocess_text(text):\n",
    "    if isinstance(text,str):\n",
    "        tokens = tokenizer.tokenize(re.sub(r'[^\\w\\s]|\\d|_*_' ,'',text.lower()))\n",
    "        pos_tags = nltk.pos_tag(tokens)\n",
    "        temp = [lemmatizer.lemmatize(i,get_wordnet_pos(tag)) for i,tag in pos_tags if i not in stop_words]\n",
    "        return \" \".join(temp)\n",
    "    return \"\"\n",
    "data_cleaned.loc[:,\"review_v2\"] = data_cleaned[\"reviewText\"].apply(preprocess_text)\n",
    "print(data_cleaned[\"review_v2\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "59b0260b-cf21-4ebd-9438-a2ee8407bdfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aaa</th>\n",
       "      <th>aaas</th>\n",
       "      <th>ab</th>\n",
       "      <th>aback</th>\n",
       "      <th>abalone</th>\n",
       "      <th>abalonefender</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abbe</th>\n",
       "      <th>abcd</th>\n",
       "      <th>...</th>\n",
       "      <th>zoneso</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zoomnow</th>\n",
       "      <th>zt</th>\n",
       "      <th>ztif</th>\n",
       "      <th>ztupdate</th>\n",
       "      <th>zune</th>\n",
       "      <th>zvex</th>\n",
       "      <th>zylgian</th>\n",
       "      <th>zz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10249</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10250</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10251</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10252</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10253</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10254 rows × 25373 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       aa  aaa  aaas  ab  aback  abalone  abalonefender  abandon  abbe  abcd  \\\n",
       "0       0    0     0   0      0        0              0        0     0     0   \n",
       "1       0    0     0   0      0        0              0        0     0     0   \n",
       "2       0    0     0   0      0        0              0        0     0     0   \n",
       "3       0    0     0   0      0        0              0        0     0     0   \n",
       "4       0    0     0   0      0        0              0        0     0     0   \n",
       "...    ..  ...   ...  ..    ...      ...            ...      ...   ...   ...   \n",
       "10249   0    0     0   0      0        0              0        0     0     0   \n",
       "10250   0    0     0   0      0        0              0        0     0     0   \n",
       "10251   0    0     0   0      0        0              0        0     0     0   \n",
       "10252   0    0     0   0      0        0              0        0     0     0   \n",
       "10253   0    0     0   0      0        0              0        0     0     0   \n",
       "\n",
       "       ...  zoneso  zoom  zoomnow  zt  ztif  ztupdate  zune  zvex  zylgian  zz  \n",
       "0      ...       0     0        0   0     0         0     0     0        0   0  \n",
       "1      ...       0     0        0   0     0         0     0     0        0   0  \n",
       "2      ...       0     0        0   0     0         0     0     0        0   0  \n",
       "3      ...       0     0        0   0     0         0     0     0        0   0  \n",
       "4      ...       0     0        0   0     0         0     0     0        0   0  \n",
       "...    ...     ...   ...      ...  ..   ...       ...   ...   ...      ...  ..  \n",
       "10249  ...       0     0        0   0     0         0     0     0        0   0  \n",
       "10250  ...       0     0        0   0     0         0     0     0        0   0  \n",
       "10251  ...       0     0        0   0     0         0     0     0        0   0  \n",
       "10252  ...       0     0        0   0     0         0     0     0        0   0  \n",
       "10253  ...       0     0        0   0     0         0     0     0        0   0  \n",
       "\n",
       "[10254 rows x 25373 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Vectorizing texts with bag-of-words\n",
    "bow_vectorizer = CountVectorizer()\n",
    "bow = bow_vectorizer.fit_transform(data_cleaned[\"review_v2\"])\n",
    "bow_dataframe = pd.DataFrame.sparse.from_spmatrix(bow,columns=bow_vectorizer.get_feature_names_out())\n",
    "bow_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "644ed1a6-2711-435f-8adb-f30bc10562de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aaa</th>\n",
       "      <th>aaas</th>\n",
       "      <th>ab</th>\n",
       "      <th>aback</th>\n",
       "      <th>abalone</th>\n",
       "      <th>abalonefender</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abbe</th>\n",
       "      <th>abcd</th>\n",
       "      <th>...</th>\n",
       "      <th>zoneso</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zoomnow</th>\n",
       "      <th>zt</th>\n",
       "      <th>ztif</th>\n",
       "      <th>ztupdate</th>\n",
       "      <th>zune</th>\n",
       "      <th>zvex</th>\n",
       "      <th>zylgian</th>\n",
       "      <th>zz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10249</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10250</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10251</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10252</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10253</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10254 rows × 25373 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        aa  aaa  aaas   ab  aback  abalone  abalonefender  abandon  abbe  \\\n",
       "0      0.0  0.0   0.0  0.0    0.0      0.0            0.0      0.0   0.0   \n",
       "1      0.0  0.0   0.0  0.0    0.0      0.0            0.0      0.0   0.0   \n",
       "2      0.0  0.0   0.0  0.0    0.0      0.0            0.0      0.0   0.0   \n",
       "3      0.0  0.0   0.0  0.0    0.0      0.0            0.0      0.0   0.0   \n",
       "4      0.0  0.0   0.0  0.0    0.0      0.0            0.0      0.0   0.0   \n",
       "...    ...  ...   ...  ...    ...      ...            ...      ...   ...   \n",
       "10249  0.0  0.0   0.0  0.0    0.0      0.0            0.0      0.0   0.0   \n",
       "10250  0.0  0.0   0.0  0.0    0.0      0.0            0.0      0.0   0.0   \n",
       "10251  0.0  0.0   0.0  0.0    0.0      0.0            0.0      0.0   0.0   \n",
       "10252  0.0  0.0   0.0  0.0    0.0      0.0            0.0      0.0   0.0   \n",
       "10253  0.0  0.0   0.0  0.0    0.0      0.0            0.0      0.0   0.0   \n",
       "\n",
       "       abcd  ...  zoneso  zoom  zoomnow   zt  ztif  ztupdate  zune  zvex  \\\n",
       "0       0.0  ...     0.0   0.0      0.0  0.0   0.0       0.0   0.0   0.0   \n",
       "1       0.0  ...     0.0   0.0      0.0  0.0   0.0       0.0   0.0   0.0   \n",
       "2       0.0  ...     0.0   0.0      0.0  0.0   0.0       0.0   0.0   0.0   \n",
       "3       0.0  ...     0.0   0.0      0.0  0.0   0.0       0.0   0.0   0.0   \n",
       "4       0.0  ...     0.0   0.0      0.0  0.0   0.0       0.0   0.0   0.0   \n",
       "...     ...  ...     ...   ...      ...  ...   ...       ...   ...   ...   \n",
       "10249   0.0  ...     0.0   0.0      0.0  0.0   0.0       0.0   0.0   0.0   \n",
       "10250   0.0  ...     0.0   0.0      0.0  0.0   0.0       0.0   0.0   0.0   \n",
       "10251   0.0  ...     0.0   0.0      0.0  0.0   0.0       0.0   0.0   0.0   \n",
       "10252   0.0  ...     0.0   0.0      0.0  0.0   0.0       0.0   0.0   0.0   \n",
       "10253   0.0  ...     0.0   0.0      0.0  0.0   0.0       0.0   0.0   0.0   \n",
       "\n",
       "       zylgian   zz  \n",
       "0          0.0  0.0  \n",
       "1          0.0  0.0  \n",
       "2          0.0  0.0  \n",
       "3          0.0  0.0  \n",
       "4          0.0  0.0  \n",
       "...        ...  ...  \n",
       "10249      0.0  0.0  \n",
       "10250      0.0  0.0  \n",
       "10251      0.0  0.0  \n",
       "10252      0.0  0.0  \n",
       "10253      0.0  0.0  \n",
       "\n",
       "[10254 rows x 25373 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Vectorizing texts with TFIDF \n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "vector = tfidf_vectorizer.fit_transform(data_cleaned[\"review_v2\"])\n",
    "tfidf_dataframe = pd.DataFrame(vector.todense(),columns=tfidf_vectorizer.get_feature_names_out())\n",
    "tfidf_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0ae18422-d696-4b5d-bd60-ede2927f6659",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining model and cross-validation strategy\n",
    "kf = KFold(n_splits=5,shuffle=True,random_state=42)\n",
    "model = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6117c16b-9384-4e6d-96cf-7c752eb1ec75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean accuracy of the bag-of-words multinomial model was 67.183% \n"
     ]
    }
   ],
   "source": [
    "#Testing bag-of-words multinomial model performance\n",
    "results_bow = cross_val_score(model,bow_dataframe,data_cleaned[\"overall\"],cv=kf,n_jobs=-1)\n",
    "print(f\"The mean accuracy of the bag-of-words multinomial model was {(results_bow.mean()*100):.3f}% \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cf84d85c-0bcb-42f1-a26d-306685327d5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean accuracy of the TFIDF multinomial model was 67.593% \n"
     ]
    }
   ],
   "source": [
    "#Testing TFIDF multinomial model performance\n",
    "results_tfidf = cross_val_score(model,tfidf_dataframe,data_cleaned[\"overall\"],cv=kf,n_jobs=-1)\n",
    "print(f\"The mean accuracy of the TFIDF multinomial model was {(results_tfidf.mean()*100):.3f}% \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "911f8153-d053-4d10-99a0-e4e1d747000a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[26,\n",
       " 661,\n",
       " 286,\n",
       " 410,\n",
       " 474,\n",
       " 361,\n",
       " 3,\n",
       " 333,\n",
       " 26,\n",
       " 997,\n",
       " 4,\n",
       " 95,\n",
       " 19,\n",
       " 361,\n",
       " 474,\n",
       " 179,\n",
       " 160,\n",
       " 10,\n",
       " 14,\n",
       " 881,\n",
       " 12,\n",
       " 1121,\n",
       " 2751]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Vectorizing texts with tensorflow\n",
    "tf_tokenizer = Tokenizer()\n",
    "tf_tokenizer.fit_on_texts(data_cleaned[\"review_v2\"])\n",
    "sequence = tf_tokenizer.texts_to_sequences(data_cleaned[\"review_v2\"])\n",
    "sequence[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "814797fe-39b9-441f-abbf-a63fdf47b2b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "206/206 [==============================] - 18s 76ms/step - loss: 1.1507 - accuracy: 0.6237 - val_loss: 0.9603 - val_accuracy: 0.6520\n",
      "Epoch 2/10\n",
      "206/206 [==============================] - 15s 74ms/step - loss: 0.9214 - accuracy: 0.6693 - val_loss: 1.0178 - val_accuracy: 0.6520\n",
      "Epoch 3/10\n",
      "206/206 [==============================] - 15s 71ms/step - loss: 0.7902 - accuracy: 0.6792 - val_loss: 1.0318 - val_accuracy: 0.6545\n",
      "Epoch 4/10\n",
      "206/206 [==============================] - 15s 73ms/step - loss: 0.6835 - accuracy: 0.7118 - val_loss: 1.1628 - val_accuracy: 0.6222\n",
      "Epoch 5/10\n",
      "206/206 [==============================] - 15s 74ms/step - loss: 0.5898 - accuracy: 0.7562 - val_loss: 1.5045 - val_accuracy: 0.6015\n",
      "Epoch 6/10\n",
      "206/206 [==============================] - 15s 73ms/step - loss: 0.4833 - accuracy: 0.8092 - val_loss: 2.2063 - val_accuracy: 0.5990\n",
      "Epoch 7/10\n",
      "206/206 [==============================] - 15s 71ms/step - loss: 0.3908 - accuracy: 0.8552 - val_loss: 1.7009 - val_accuracy: 0.5082\n",
      "Epoch 8/10\n",
      "206/206 [==============================] - 15s 72ms/step - loss: 0.3402 - accuracy: 0.8750 - val_loss: 2.1037 - val_accuracy: 0.4869\n",
      "Epoch 9/10\n",
      "206/206 [==============================] - 15s 74ms/step - loss: 0.2716 - accuracy: 0.9019 - val_loss: 2.8200 - val_accuracy: 0.5594\n",
      "Epoch 10/10\n",
      "206/206 [==============================] - 16s 76ms/step - loss: 0.2266 - accuracy: 0.9197 - val_loss: 2.8544 - val_accuracy: 0.5472\n",
      "65/65 [==============================] - 1s 10ms/step - loss: 2.7554 - accuracy: 0.5783\n",
      "The test accuracy was 57.825%\n"
     ]
    }
   ],
   "source": [
    "#Creating a SimpleRNN with embedding layer\n",
    "max_length = 10\n",
    "padded_sequence = tf.keras.preprocessing.sequence.pad_sequences(sequence,maxlen=max_length,padding=\"post\")\n",
    "vocab_size=23889\n",
    "embedding_dim=100\n",
    "model_simple = tf.keras.models.Sequential()\n",
    "model_simple.add(tf.keras.layers.Embedding(input_dim=vocab_size,output_dim=embedding_dim,input_length=max_length))\n",
    "model_simple.add(tf.keras.layers.SimpleRNN(64,activation=\"relu\",return_sequences=True))\n",
    "model_simple.add(tf.keras.layers.Dropout(0.5))\n",
    "model_simple.add(tf.keras.layers.SimpleRNN(32,activation=\"relu\"))\n",
    "model_simple.add(tf.keras.layers.Dropout(0.5))\n",
    "model_simple.add(tf.keras.layers.Dense(6,activation=\"softmax\"))\n",
    "model_simple.compile(loss=\"sparse_categorical_crossentropy\",metrics=[\"accuracy\"],optimizer=\"adam\")\n",
    "\n",
    "x_full,x_test,y_full,y_test=train_test_split(padded_sequence,data_cleaned[\"overall\"],random_state=42,test_size=0.2)\n",
    "x_train,x_valid,y_train,y_valid = train_test_split(x_full,y_full,random_state=42,test_size=0.2)\n",
    "model_simple.fit(x_train,y_train,epochs=10,validation_data=(x_valid,y_valid))\n",
    "test_loss,test_acc = model_simple.evaluate(x_test,y_test)\n",
    "print(f\"The test accuracy was {100*test_acc:.3f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "cf6fcca4-0076-4f47-8d2e-4b4055f767a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "206/206 [==============================] - 7s 19ms/step - loss: 3.8120 - accuracy: 0.6713 - val_loss: 1.0079 - val_accuracy: 0.6520\n",
      "Epoch 2/10\n",
      "206/206 [==============================] - 3s 15ms/step - loss: 0.9649 - accuracy: 0.6743 - val_loss: 0.9881 - val_accuracy: 0.6520\n",
      "Epoch 3/10\n",
      "206/206 [==============================] - 3s 16ms/step - loss: 0.9649 - accuracy: 0.6743 - val_loss: 1.0101 - val_accuracy: 0.6520\n",
      "Epoch 4/10\n",
      "206/206 [==============================] - 3s 16ms/step - loss: 0.9633 - accuracy: 0.6743 - val_loss: 0.9879 - val_accuracy: 0.6520\n",
      "Epoch 5/10\n",
      "206/206 [==============================] - 3s 16ms/step - loss: 0.9625 - accuracy: 0.6743 - val_loss: 0.9870 - val_accuracy: 0.6520\n",
      "Epoch 6/10\n",
      "206/206 [==============================] - 3s 16ms/step - loss: 0.9604 - accuracy: 0.6743 - val_loss: 0.9892 - val_accuracy: 0.6520\n",
      "Epoch 7/10\n",
      "206/206 [==============================] - 3s 16ms/step - loss: 0.9604 - accuracy: 0.6743 - val_loss: 0.9901 - val_accuracy: 0.6520\n",
      "Epoch 8/10\n",
      "206/206 [==============================] - 3s 16ms/step - loss: 0.9612 - accuracy: 0.6743 - val_loss: 0.9870 - val_accuracy: 0.6520\n",
      "Epoch 9/10\n",
      "206/206 [==============================] - 3s 16ms/step - loss: 0.9607 - accuracy: 0.6743 - val_loss: 0.9880 - val_accuracy: 0.6520\n",
      "Epoch 10/10\n",
      "206/206 [==============================] - 3s 15ms/step - loss: 0.9596 - accuracy: 0.6743 - val_loss: 0.9916 - val_accuracy: 0.6520\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.9298 - accuracy: 0.7006\n",
      "The test accuracy was 70.063%\n"
     ]
    }
   ],
   "source": [
    "#Creating RNN Unidirectional LSTM with embedding layer\n",
    "max_length = 10\n",
    "padded_sequence = tf.keras.preprocessing.sequence.pad_sequences(sequence,maxlen=max_length,padding=\"post\")\n",
    "vocab_size=23889\n",
    "embedding_dim=100\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(input_dim=vocab_size,output_dim=embedding_dim,input_length=max_length))\n",
    "model.add(tf.keras.layers.LSTM(64,return_sequences=True,kernel_regularizer=regularizers.l2(0.06)))\n",
    "model.add(tf.keras.layers.Dropout(0.1))\n",
    "model.add(tf.keras.layers.LSTM(64,kernel_regularizer=regularizers.l2(0.06)))\n",
    "model.add(tf.keras.layers.Dropout(0.1))\n",
    "model.add(tf.keras.layers.Dense(6,activation=\"softmax\"))\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",metrics=[\"accuracy\"],optimizer=\"adam\")\n",
    "\n",
    "x_full,x_test,y_full,y_test=train_test_split(padded_sequence,data_cleaned[\"overall\"],random_state=42,test_size=0.2)\n",
    "x_train,x_valid,y_train,y_valid = train_test_split(x_full,y_full,random_state=42,test_size=0.2)\n",
    "model.fit(x_train,y_train,epochs=10,validation_data=(x_valid,y_valid))\n",
    "test_loss,test_acc = model.evaluate(x_test,y_test)\n",
    "print(f\"The test accuracy was {100*test_acc:.3f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d8388635-ffbf-43d5-b139-9732020f1005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "206/206 [==============================] - 13s 32ms/step - loss: 5.0058 - accuracy: 0.6714 - val_loss: 1.0092 - val_accuracy: 0.6520\n",
      "Epoch 2/10\n",
      "206/206 [==============================] - 5s 23ms/step - loss: 0.9729 - accuracy: 0.6743 - val_loss: 1.0158 - val_accuracy: 0.6520\n",
      "Epoch 3/10\n",
      "206/206 [==============================] - 5s 22ms/step - loss: 0.9665 - accuracy: 0.6743 - val_loss: 0.9963 - val_accuracy: 0.6520\n",
      "Epoch 4/10\n",
      "206/206 [==============================] - 5s 22ms/step - loss: 0.9657 - accuracy: 0.6743 - val_loss: 0.9896 - val_accuracy: 0.6520\n",
      "Epoch 5/10\n",
      "206/206 [==============================] - 5s 23ms/step - loss: 0.9649 - accuracy: 0.6743 - val_loss: 0.9914 - val_accuracy: 0.6520\n",
      "Epoch 6/10\n",
      "206/206 [==============================] - 5s 23ms/step - loss: 0.9624 - accuracy: 0.6743 - val_loss: 0.9882 - val_accuracy: 0.6520\n",
      "Epoch 7/10\n",
      "206/206 [==============================] - 5s 23ms/step - loss: 0.9635 - accuracy: 0.6743 - val_loss: 0.9926 - val_accuracy: 0.6520\n",
      "Epoch 8/10\n",
      "206/206 [==============================] - 5s 23ms/step - loss: 0.9628 - accuracy: 0.6743 - val_loss: 0.9944 - val_accuracy: 0.6520\n",
      "Epoch 9/10\n",
      "206/206 [==============================] - 5s 25ms/step - loss: 0.9602 - accuracy: 0.6743 - val_loss: 0.9867 - val_accuracy: 0.6520\n",
      "Epoch 10/10\n",
      "206/206 [==============================] - 5s 24ms/step - loss: 0.9619 - accuracy: 0.6743 - val_loss: 0.9869 - val_accuracy: 0.6520\n",
      "65/65 [==============================] - 1s 12ms/step - loss: 0.9345 - accuracy: 0.7006\n",
      "The test accuracy was 70.063%\n"
     ]
    }
   ],
   "source": [
    "#Creating RNN Bidirectional LSTM with embedding layer\n",
    "max_length = 10\n",
    "padded_sequence = tf.keras.preprocessing.sequence.pad_sequences(sequence,maxlen=max_length,padding=\"post\")\n",
    "vocab_size=23889\n",
    "embedding_dim=100\n",
    "model_bi = tf.keras.models.Sequential()\n",
    "model_bi.add(tf.keras.layers.Embedding(input_dim=vocab_size,output_dim=embedding_dim,input_length=max_length))\n",
    "model_bi.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64,return_sequences=True,kernel_regularizer=regularizers.l2(0.035))))\n",
    "model_bi.add(tf.keras.layers.Dropout(0.2))\n",
    "model_bi.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64,kernel_regularizer=regularizers.l2(0.035))))\n",
    "model_bi.add(tf.keras.layers.Dropout(0.3))\n",
    "model_bi.add(tf.keras.layers.Dense(6,activation=\"softmax\"))\n",
    "model_bi.compile(loss=\"sparse_categorical_crossentropy\",metrics=[\"accuracy\"],optimizer=\"adam\")\n",
    "\n",
    "x_full,x_test,y_full,y_test=train_test_split(padded_sequence,data_cleaned[\"overall\"],random_state=42,test_size=0.2)\n",
    "x_train,x_valid,y_train,y_valid = train_test_split(x_full,y_full,random_state=42,test_size=0.2)\n",
    "model_bi.fit(x_train,y_train,epochs=10,validation_data=(x_valid,y_valid))\n",
    "test_loss,test_acc = model_bi.evaluate(x_test,y_test)\n",
    "print(f\"The test accuracy was {100*test_acc:.3f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5b5af5-7a34-46af-ac33-2a50799f9794",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kernel TF",
   "language": "python",
   "name": "tensorflow_v2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

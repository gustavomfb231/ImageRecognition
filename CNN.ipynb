{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb9ca800-b3eb-4f96-aeb8-33b84117dcd9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "from tensorflow.keras.applications.vgg16 import VGG16,preprocess_input,decode_predictions\n",
    "import numpy as np\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9bb49ad-a677-446f-827d-08a241de6e65",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "#Reading and splitting the images in train,validation and test\n",
    "animals_path = \"C:\\\\Users\\\\USUARIO\\\\animals\"\n",
    "animals_train_path = \"C:\\\\Users\\\\USUARIO\\\\animals_train\"\n",
    "animals_test_path = \"C:\\\\Users\\\\USUARIO\\\\animals_test\"\n",
    "animals_valid_path = \"C:\\\\Users\\\\USUARIO\\\\animals_valid\"\n",
    "subcategories = [\"cats\",\"dogs\",\"panda\"]\n",
    "train_ratio = 0.8\n",
    "for subcategory in subcategories:\n",
    "    subcategory_folder = os.path.join(animals_path,subcategory)\n",
    "    image_files = sorted(os.listdir(subcategory_folder))\n",
    "    num = int(len(image_files) * train_ratio)\n",
    "    test_num = int(len(image_files) - num)\n",
    "    train_subfolder = os.path.join(animals_train_path, subcategory)\n",
    "    test_subfolder = os.path.join(animals_test_path, subcategory)\n",
    "    valid_subfolder = os.path.join(animals_valid_path,subcategory)\n",
    "    os.makedirs(train_subfolder, exist_ok=True)\n",
    "    os.makedirs(test_subfolder, exist_ok=True)\n",
    "    os.makedirs(valid_subfolder,exist_ok=True)\n",
    "    for index,i in enumerate(image_files):\n",
    "        source_path = os.path.join(subcategory_folder,i)\n",
    "        if index < num:\n",
    "            if index  < int(num*train_ratio):\n",
    "                destination_path = os.path.join(train_subfolder,i)\n",
    "            else:\n",
    "                destination_path = os.path.join(valid_subfolder,i)\n",
    "        else:\n",
    "            destination_path = os.path.join(test_subfolder,i)\n",
    "        shutil.copyfile(source_path,destination_path)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3596c5cf-8e90-4bb7-9182-e7e228a276d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1920 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1.0/255,\n",
    "                                  rotation_range=20,\n",
    "                                  width_shift_range=0.2,\n",
    "                                  height_shift_range=0.2,\n",
    "                                  shear_range=0.2,zoom_range=0.2,\n",
    "                                  horizontal_flip=True,\n",
    "                                  fill_mode='nearest')\n",
    "data_train = train_datagen.flow_from_directory(\n",
    "    directory=animals_train_path,\n",
    "    target_size=(224,224),\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=32,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf890e33-a686-455a-a7ff-34bc8e03c5b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 480 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "valid_datagen = ImageDataGenerator(rescale=1.0/255,\n",
    "                                  rotation_range=20,\n",
    "                                  width_shift_range=0.2,\n",
    "                                  height_shift_range=0.2,\n",
    "                                  shear_range=0.2,zoom_range=0.2,\n",
    "                                  horizontal_flip=True,\n",
    "                                  fill_mode='nearest')\n",
    "data_valid= valid_datagen.flow_from_directory(\n",
    "    directory=animals_valid_path,\n",
    "    target_size=(224,224),\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=32,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f9252e7-c074-4fd1-8b3d-baf3870bdfcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 600 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1.0/255,\n",
    "                                  rotation_range=20,\n",
    "                                  width_shift_range=0.2,\n",
    "                                  height_shift_range=0.2,\n",
    "                                  shear_range=0.2,zoom_range=0.2,\n",
    "                                  horizontal_flip=True,\n",
    "                                  fill_mode='nearest')\n",
    "data_test = test_datagen.flow_from_directory(\n",
    "    directory=animals_test_path,\n",
    "    target_size=(224,224),\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=32,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbfc4945-ea70-4e12-9ba1-1ed550fd3297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3000 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "full_datagen = ImageDataGenerator()\n",
    "data_full = full_datagen.flow_from_directory(\n",
    "    directory=\"C:\\\\Users\\\\USUARIO\\\\animals\",\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=32,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c687025-7f5d-4d9d-9ddd-32710f9809bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60/60 [==============================] - 67s 883ms/step - loss: 1.6000 - accuracy: 0.4365 - val_loss: 0.9170 - val_accuracy: 0.5437\n",
      "Epoch 2/5\n",
      "60/60 [==============================] - 38s 632ms/step - loss: 0.9190 - accuracy: 0.5547 - val_loss: 0.8468 - val_accuracy: 0.5625\n",
      "Epoch 3/5\n",
      "60/60 [==============================] - 36s 603ms/step - loss: 0.8467 - accuracy: 0.5641 - val_loss: 0.7428 - val_accuracy: 0.6062\n",
      "Epoch 4/5\n",
      "60/60 [==============================] - 36s 607ms/step - loss: 0.7738 - accuracy: 0.6146 - val_loss: 0.6900 - val_accuracy: 0.6708\n",
      "Epoch 5/5\n",
      "60/60 [==============================] - 38s 637ms/step - loss: 0.7651 - accuracy: 0.6193 - val_loss: 0.6721 - val_accuracy: 0.6687\n",
      "19/19 [==============================] - 15s 817ms/step - loss: 0.7546 - accuracy: 0.6283\n",
      "Test accuracy was 62.833%\n"
     ]
    }
   ],
   "source": [
    "#Convolutional Neural Network\n",
    "def cnn():\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Conv2D(filters=32,activation=\"relu\",kernel_size=(3,3),input_shape=(224,224,3)))\n",
    "    model.add(keras.layers.MaxPool2D())\n",
    "    model.add(keras.layers.Conv2D(filters=64,activation=\"relu\",kernel_size=(5,5)))\n",
    "    model.add(keras.layers.MaxPool2D())\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(256,activation=\"relu\"))\n",
    "    model.add(keras.layers.Dense(64,activation=\"relu\"))\n",
    "    model.add(keras.layers.Dense(3,activation=\"softmax\")) \n",
    "    model.compile(loss=\"categorical_crossentropy\",optimizer=\"adam\",metrics=[\"accuracy\"])\n",
    "    return model\n",
    "def train_test(model):\n",
    "    model.fit(data_train,validation_data=data_valid,epochs=5)\n",
    "    test_loss,test_acc = model.evaluate(data_test)\n",
    "    return test_loss,test_acc\n",
    "test_loss,test_acc = train_test(cnn())\n",
    "print(f\"Test accuracy was {(test_acc*100):.3f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f7980c-5177-476d-9e2a-1601d94ec56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if len(physical_devices) > 0:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "else:\n",
    "    print(\"0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "570b0923-4d14-4e56-b0d0-fc47b2388d8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60/60 [==============================] - 49s 683ms/step - loss: 0.9919 - accuracy: 0.5651 - val_loss: 0.8458 - val_accuracy: 0.7229\n",
      "Epoch 2/5\n",
      "60/60 [==============================] - 38s 638ms/step - loss: 0.7586 - accuracy: 0.7411 - val_loss: 0.6934 - val_accuracy: 0.7542\n",
      "Epoch 3/5\n",
      "60/60 [==============================] - 36s 593ms/step - loss: 0.6013 - accuracy: 0.7880 - val_loss: 0.5743 - val_accuracy: 0.8000\n",
      "Epoch 4/5\n",
      "60/60 [==============================] - 36s 599ms/step - loss: 0.5025 - accuracy: 0.8302 - val_loss: 0.5289 - val_accuracy: 0.8083\n",
      "Epoch 5/5\n",
      "60/60 [==============================] - 37s 611ms/step - loss: 0.4521 - accuracy: 0.8417 - val_loss: 0.4565 - val_accuracy: 0.8313\n",
      "19/19 [==============================] - 13s 696ms/step - loss: 0.4355 - accuracy: 0.8667\n",
      "Test accuracy was 86.667%\n"
     ]
    }
   ],
   "source": [
    "#State-of-art convolutional neural network model VGG16 Transfer Learning\n",
    "model_vgg16 = VGG16(weights=\"imagenet\",include_top=False,input_shape=(224,224,3))\n",
    "for layer in model_vgg16.layers:\n",
    "    layer.trainable=False\n",
    "model_transfer = keras.models.Sequential()\n",
    "model_transfer.add(model_vgg16)\n",
    "model_transfer.add(keras.layers.GlobalAveragePooling2D())\n",
    "model_transfer.add(keras.layers.Dense(64,activation=\"relu\"))\n",
    "model_transfer.add(keras.layers.Dense(3,activation=\"softmax\"))\n",
    "model_transfer.compile(loss=\"categorical_crossentropy\",metrics=[\"accuracy\"],optimizer=\"adam\")\n",
    "history  = model_transfer.fit(data_train,validation_data=data_valid,epochs=5)\n",
    "test_loss,test_acc = model_transfer.evaluate(data_test)\n",
    "print(f\"Test accuracy was {(test_acc*100):.3f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4918bf9d-507a-44dd-9e45-15f7cbc528dc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.experimental.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5fc742-28af-4863-9eab-4d2dd58ce3db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kernel TF",
   "language": "python",
   "name": "tensorflow_v2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
